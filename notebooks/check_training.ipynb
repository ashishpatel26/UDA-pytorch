{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_train_test_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_labelled_loader, train_unlabelled_loader, test_loader = \\\n",
    "    get_train_test_loaders(dataset_name=\"CIFAR10\", \n",
    "                           num_labelled_samples=4000,\n",
    "                           path=\"../input/cifar10\",\n",
    "                           batch_size=16,\n",
    "                           unlabelled_batch_size=32,\n",
    "                           num_workers=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "config = {\n",
    "    \"dataset\": \"CIFAR10\",\n",
    "    \"data_path\": \".\",\n",
    "\n",
    "    \"model\": \"fastresnet\",\n",
    "\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"unlabelled_batch_size\": 320,\n",
    "    \"num_workers\": 10,\n",
    "\n",
    "    \"num_epochs\": num_epochs,\n",
    "\n",
    "    \"lr_milestones_values\": [(0, 0.0), (5, 1.0), (num_epochs, 0.0)],\n",
    "\n",
    "    \"num_labelled_samples\": 4000,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(config['model'])\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.0,\n",
    "                      momentum=config['momentum'],\n",
    "                      weight_decay=config['weight_decay'],\n",
    "                      nesterov=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "consistency_criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.contrib.handlers import PiecewiseLinear\n",
    "\n",
    "\n",
    "le = len(train_labelled_loader)\n",
    "milestones_values = [(le * m, v) for m, v in config['lr_milestones_values']]\n",
    "scheduler = PiecewiseLinear(optimizer, \"lr\", milestones_values=milestones_values)\n",
    "\n",
    "def _prepare_batch(batch, device, non_blocking):\n",
    "    x, y = batch\n",
    "    return (convert_tensor(x, device=device, non_blocking=non_blocking),\n",
    "            convert_tensor(y, device=device, non_blocking=non_blocking))\n",
    "\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for i in iterable:\n",
    "            yield i\n",
    "\n",
    "train_unlabelled_loader_iter = cycle(train_unlabelled_loader)\n",
    "train_labelled_loader_iter = cycle(train_labelled_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_x, unsup_aug_x = next(train_unlabelled_loader_iter)\n",
    "labelled_batch = next(train_labelled_loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.utils import convert_tensor\n",
    "\n",
    "\n",
    "x, y = _prepare_batch(labelled_batch, device=device, non_blocking=True)\n",
    "unsup_x = convert_tensor(unsup_x, device=device, non_blocking=True)\n",
    "unsup_aug_x = convert_tensor(unsup_aug_x, device=device, non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "# Supervised part        \n",
    "y_pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1528, -0.1141, -0.0512, -0.1139, -0.0534,  0.1363,  0.0660, -0.2587,\n",
       "         -0.1338,  0.1013],\n",
       "        [-0.0366, -0.0968, -0.0015, -0.0371, -0.0577,  0.1379,  0.0684, -0.1793,\n",
       "         -0.1218,  0.0842],\n",
       "        [-0.0623, -0.0666,  0.0254, -0.1177, -0.0480,  0.1450,  0.0931, -0.1944,\n",
       "         -0.2085,  0.0915],\n",
       "        [-0.0821, -0.0944,  0.0107, -0.0844,  0.0015,  0.1568,  0.1070, -0.2398,\n",
       "         -0.1294,  0.1367],\n",
       "        [-0.1292, -0.0873,  0.0641, -0.0344, -0.0791,  0.1556,  0.1828, -0.2433,\n",
       "         -0.1491,  0.1579],\n",
       "        [-0.0876, -0.1499,  0.0490, -0.1176, -0.0755,  0.1589,  0.1416, -0.1794,\n",
       "         -0.2034,  0.1096],\n",
       "        [-0.1641, -0.0606,  0.0983, -0.0849, -0.1453,  0.1362,  0.1545, -0.3549,\n",
       "         -0.2024,  0.1620],\n",
       "        [-0.0421, -0.1143, -0.0493, -0.0796,  0.0319,  0.0496,  0.0486, -0.1292,\n",
       "         -0.1355,  0.0986],\n",
       "        [-0.1042, -0.0773,  0.0064, -0.0575, -0.0168,  0.1594,  0.0885, -0.2316,\n",
       "         -0.1100,  0.1103],\n",
       "        [-0.0978, -0.0612,  0.0340, -0.0544,  0.0396,  0.1273,  0.0334, -0.1858,\n",
       "         -0.1418,  0.0968],\n",
       "        [-0.0775, -0.0712,  0.0198, -0.0888,  0.0692,  0.0968,  0.0434, -0.1956,\n",
       "         -0.1863,  0.0495],\n",
       "        [-0.0888, -0.0454,  0.0190, -0.0585, -0.0756,  0.1166,  0.1094, -0.2132,\n",
       "         -0.1309,  0.0988],\n",
       "        [-0.0477, -0.0680,  0.0228, -0.0605,  0.0046,  0.0778,  0.0256, -0.1376,\n",
       "         -0.1157,  0.1028],\n",
       "        [-0.0388, -0.0650, -0.0033, -0.0866,  0.0293,  0.1096,  0.0291, -0.1259,\n",
       "         -0.1185,  0.0779],\n",
       "        [-0.1128, -0.0782,  0.0673, -0.0946, -0.0258,  0.0843,  0.0890, -0.1336,\n",
       "         -0.1454,  0.1219],\n",
       "        [-0.0526, -0.0983,  0.0037, -0.0752,  0.0310,  0.0979,  0.0786, -0.1198,\n",
       "         -0.1121,  0.0985]], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = torch.linspace(0.1, 1.0, steps=len(train_labelled_loader) * config['num_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000000149011612"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "def foo(y_pred, y, step):\n",
    "    t = thresholds[step].item()\n",
    "    y_pred_softmax = torch.softmax(y_pred, dim=1)\n",
    "    res = y_pred_softmax.gather(dim=1, index=y.unsqueeze(dim=1))\n",
    "    print(res)\n",
    "    mask = (res < t).squeeze(dim=1)\n",
    "    print(mask)\n",
    "    if mask.sum() > 0:            \n",
    "        return y_pred[mask], y[mask]\n",
    "\n",
    "    warnings.warn(\"Threshold {} is too low, all predictions are discarded.\\n\".format(t) +\n",
    "                  \"y_pred.min/max: {}, {}\".format(res.min(), res.max()))\n",
    "    return y_pred, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1164],\n",
      "        [0.1018],\n",
      "        [0.0846],\n",
      "        [0.0891],\n",
      "        [0.0922],\n",
      "        [0.0941],\n",
      "        [0.1183],\n",
      "        [0.1081],\n",
      "        [0.0807],\n",
      "        [0.1120],\n",
      "        [0.1134],\n",
      "        [0.0976],\n",
      "        [0.1022],\n",
      "        [0.0896],\n",
      "        [0.0941],\n",
      "        [0.1043]], device='cuda:0', grad_fn=<GatherBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0], device='cuda:0',\n",
      "       dtype=torch.uint8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0966, 0.0962, 0.1054, 0.0914, 0.0980, 0.1188, 0.1128, 0.0846, 0.0835,\n",
       "          0.1127],\n",
       "         [0.0935, 0.0923, 0.1025, 0.0932, 0.1016, 0.1187, 0.1129, 0.0798, 0.0891,\n",
       "          0.1163],\n",
       "         [0.0884, 0.0922, 0.1073, 0.0972, 0.0930, 0.1176, 0.1208, 0.0789, 0.0867,\n",
       "          0.1179],\n",
       "         [0.0941, 0.0884, 0.1079, 0.0913, 0.0952, 0.1204, 0.1183, 0.0859, 0.0838,\n",
       "          0.1146],\n",
       "         [0.0916, 0.0941, 0.1024, 0.0960, 0.1000, 0.1193, 0.1111, 0.0807, 0.0911,\n",
       "          0.1136],\n",
       "         [0.0935, 0.0976, 0.1041, 0.0964, 0.0947, 0.1148, 0.1140, 0.0825, 0.0896,\n",
       "          0.1128],\n",
       "         [0.0978, 0.0952, 0.1013, 0.0932, 0.1047, 0.1134, 0.1046, 0.0896, 0.0903,\n",
       "          0.1099],\n",
       "         [0.0909, 0.0941, 0.1089, 0.0926, 0.0992, 0.1108, 0.1113, 0.0891, 0.0880,\n",
       "          0.1150]], device='cuda:0', grad_fn=<IndexBackward>),\n",
       " tensor([7, 8, 1, 0, 7, 1, 7, 1], device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo(y_pred, y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred, y = tsa(y_pred, y, step=engine.state.iteration - 1)\n",
    "\n",
    "loss = criterion(y_pred, y)\n",
    "\n",
    "# Unsupervised part\n",
    "y_pred_a = model(unsup_x)\n",
    "y_pred_b = model(unsup_aug_x)\n",
    "consistency_loss = consistency_criterion(y_pred_a, y_pred_b)\n",
    "\n",
    "final_loss = loss + lam * consistency_loss\n",
    "\n",
    "optimizer.zero_grad()\n",
    "final_loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
